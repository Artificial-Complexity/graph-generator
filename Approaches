#Approach

Suggestion 1:
We frame the problem of finding lower bounds for the algorithm MIS using reinforcement learning (RL) as follows:
* State: A partially constructed graph (maybe we set the nodes number to sth small at first)
* Action: Adding vertices or edges to the graph
* Reward: A measure of the graph's difficulty for the given algorithm (most difficult part)
  - how to count the number of nodes in a search tree?
* Goal: Construct a graph that maximizes the algorithm's runtime (reward)
  - Note that we do not consider what happens within a node but the number of nodes in a search tree. 
This formulation allows the RL agent to iteratively build graphs that challenge the MIS algorithm.

